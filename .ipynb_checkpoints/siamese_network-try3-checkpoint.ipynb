{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6477c789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 23:53:30.774154: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Conv2D,MaxPool2D,GlobalMaxPool2D,Flatten,Dense,Dropout,Input,Lambda,BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping, ReduceLROnPlateau\n",
    "import keras.backend as K\n",
    "import librosa\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from sklearn.utils import shuffle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "637cddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert song to mel spectogram as siamese network doesn't work on sound directly\n",
    "def create_spectrogram(clip,sample_rate,save_path):\n",
    "    plt.interactive(False)\n",
    "    fig=plt.figure(figsize=[0.72,0.72])\n",
    "    ax=fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    S=librosa.feature.melspectrogram(y=clip,sr=sample_rate)\n",
    "    librosa.display.specshow(librosa.power_to_db(S,ref=np.max))\n",
    "    fig.savefig(save_path,dpi=400,bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()\n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    del save_path,clip,sample_rate,fig,ax,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6b27a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder of siamese network\n",
    "# def get_encoder(input_size):\n",
    "#     #convolutional neural network layers\n",
    "#     model=Sequential()\n",
    "#     model.add(Conv2D(32,(3,3),input_shape=(150,150,3),activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "#     model.add(MaxPool2D(2,2))\n",
    "#     model.add(Dropout(0.5))\n",
    "\n",
    "#     model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "#     model.add(MaxPool2D(2,2))\n",
    "#     model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "#     model.add(GlobalMaxPool2D())\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6af2686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "def get_encoder(input_size):\n",
    "    # Use VGG16 as the encoder\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_size)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPool2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    encoder = Model(inputs=base_model.input, outputs=x)\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "197cefd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 23:53:42.451264: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def get_siamese_network(encoder,input_size):\n",
    "    \n",
    "    #define tensors of 2 input\n",
    "    input1=Input(input_size)\n",
    "    input2=Input(input_size)\n",
    "\n",
    "    #generate encoding i.e (feature vector) of the 2 imgs\n",
    "    encoder_l=encoder(input1)\n",
    "    encoder_r=encoder(input2)\n",
    "    \n",
    "    #add customized layer to compute absolute diff between encoding\n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoder_l, encoder_r])\n",
    "        \n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    output=Dense(1,activation='sigmoid')(L1_distance)\n",
    "    \n",
    "    #connect inputs with output\n",
    "    siam_model=Model(inputs=[input1,input2],outputs=output)\n",
    "    return siam_model\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom metric function to calculate accuracy.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    false_negatives = K.sum(K.round(K.clip(y_true * (1-y_pred), 0, 1)))\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    false_positives = K.sum(K.round(K.clip((1-y_true) * y_pred, 0, 1)))\n",
    "\n",
    "    accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives + K.epsilon())\n",
    "    return accuracy\n",
    "\n",
    "encoder=get_encoder((150,150,3))\n",
    "siamese_net=get_siamese_network(encoder,(150,150,3))\n",
    "siamese_net.compile(loss='binary_crossentropy',optimizer='adam',metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7acb6d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# Use data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dbff110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tar= target var\n",
    "def different_label_index(X):\n",
    "    idx1=0\n",
    "    idx2=0\n",
    "    while idx1==idx2:\n",
    "        idx1=np.random.randint(0,len(X))\n",
    "        idx2=np.random.randint(0,len(X))\n",
    "    return idx1,idx2\n",
    "\n",
    "def load_img(path):\n",
    "    img=cv2.imread(path)\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    img=cv2.resize(img,(150,150))\n",
    "    return img\n",
    "\n",
    "\n",
    "def batch_generator(X,batch_size):\n",
    "    while True:\n",
    "        data=[np.zeros((batch_size,150,150,3)) for i in range(2)]\n",
    "        tar=[np.zeros(batch_size,)]\n",
    "\n",
    "        #Generating same pairs.\n",
    "        for i in range(0,batch_size//2):\n",
    "            idx1=np.random.randint(0,len(X))\n",
    "            img1=load_img(X[idx1])\n",
    "            img1=img1/255\n",
    "\n",
    "            data[0][i,:,:,:]=img1\n",
    "            data[1][i,:,:,:]=img1\n",
    "            tar[0][i]=1\n",
    "\n",
    "        #Generating different pairs.\n",
    "        for k in range(batch_size//2,batch_size):\n",
    "            idx1,idx2=different_label_index(X)\n",
    "            img1=load_img(X[idx1])\n",
    "            img1=img1/255\n",
    "            img2=load_img(X[idx2])\n",
    "            img2=img2/255\n",
    "\n",
    "            data[0][k,:,:,:]=img1\n",
    "            data[1][k,:,:,:]=img2\n",
    "            tar[0][k]=0\n",
    "        np.delete(data[0],np.where(~data[0].any(axis=1))[0], axis=0) #Remove the data points in case they have zero value.\n",
    "        np.delete(data[1],np.where(~data[1].any(axis=1))[0], axis=0) \n",
    "        yield data,tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fb31983",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine Dragons-Bones.mp3\n",
      "A.R. Rahman,Arijit Singh - Enna Sona.mp3\n",
      "Shankar-Ehsaan-Loy,Shankar Mahadevan - Aaj Kal Zindagi.mp3\n",
      "Sohail Sen,Benny Dayal,Aditi Singh Sharma,Irshad Kamil - Choomantar.mp3\n",
      "#Eminem, Royce Da 5'9##, Black Thought, Q-Tip, Denaun# - #Yah Yah (feat. Royce Da 5'9##, Black Thought, Q-Tip & Denaun)#.mp3\n",
      "Vishal Dadlani,Shilpa Rao - I Feel Good.mp3\n",
      "Aditi Singh Sharma,Amitabh Bhattacharya - Offo.mp3\n",
      "Mohit Chauhan - Masakali.mp3\n",
      "#Eminem, Royce Da 5'9##, White Gold# - #You Gonâ€™ Learn (feat. Royce Da 5'9## & White Gold)#.mp3\n",
      "Anuv Jain - Alag Aasmaan.mp3\n",
      "#Eminem, KXNG Crooked, Royce Da 5'9##, Joell Ortiz# - #I Will (feat. KXNG Crooked, Royce Da 5'9## & Joell Ortiz)#.mp3\n",
      "Sonu Nigam,Jayesh Gandhi,Amrita Kak - Just Chill.mp3\n",
      "Sanam - Gulabi Aankhen.mp3\n",
      "stephen sanchez, em beihold-until i found you.mp3\n",
      "AP Dhillon,Gurinder Gill,Intense - Excuses.mp3\n",
      "Sohail Sen,Rahat Fateh Ali Khan,Irshad Kamil - Isq Risk.mp3\n",
      "Eminem, Juice WRLD - Godzilla (feat. Juice WRLD).mp3\n",
      "Shaan,KK - Dus Bahane.mp3\n",
      "Amit Trivedi - Namo Namo.mp3\n",
      "Indila-Tourner Dans Le Vide.mp3\n",
      "Amit Trivedi - Naina Da Kya Kasoor.mp3\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "# Lists all the files in the folder.\n",
    "songs_list = [f for f in os.listdir('/Users/prernachheda/Desktop/chord/seismese_net_songs') if not f.startswith('.')]\n",
    "\n",
    "\n",
    "\n",
    "counter = 1\n",
    "def get_spec_name(song_name):\n",
    "    global counter\n",
    "    spec_name = f\"{song_name}_{counter}.png\"\n",
    "    counter += 1\n",
    "    return spec_name\n",
    "\n",
    "for song in songs_list:\n",
    "    print(song)\n",
    "    songfile, sr = librosa.load('/Users/prernachheda/Desktop/chord/seismese_net_songs/'+song)\n",
    "    duration = librosa.get_duration(y=songfile, sr=sr)\n",
    "    # Apply pre-emphasis filter\n",
    "    preemphasis_coeff = 0.07\n",
    "    preemphasis_filter = np.array([1, -preemphasis_coeff])\n",
    "    songfile = scipy.signal.lfilter(preemphasis_filter, [1], songfile.ravel())\n",
    "    song_name = os.path.splitext(song)[0]\n",
    "    prev = 0\n",
    "    for i in range(1, int((duration // 10) + 1)):\n",
    "        if i == int((duration // 10)):\n",
    "            \"\"\"Since we are dividing the song in 10s segment there might be case that after taking 10\n",
    "            fragments also few more seconds are left so in this case extra becomes extra=extra+(10-extra) \n",
    "            from the previous segment.\"\"\"\n",
    "            extra = int((int(duration) / 10 - int(int(duration) / 10)) * 10) \n",
    "            st = (sr * i * 10) - (10 - extra)\n",
    "            end = st + 10\n",
    "            songfrag = np.copy(songfile[st:end])\n",
    "        else:\n",
    "            songfrag = np.copy(songfile[prev:(sr * i * 10)])\n",
    "        \n",
    "            specname = get_spec_name(song_name)\n",
    "            create_spectrogram(songfrag, sr, '/Users/prernachheda/Desktop/chord/test_spect/' + specname)\n",
    "        \n",
    "        prev = sr * i * 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96c3a1ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rb/1jv_n39j7wl_3m_rzkqc15fh0000gp/T/ipykernel_5107/2173544395.py:11: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history=siamese_net.fit_generator(batch_generator(X_train,batch_size),steps_per_epoch=len(X_train)//batch_size,epochs=80,validation_data=batch_generator(X_test,batch_size),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.7102 - accuracy: 0.5590\n",
      "Epoch 1: val_loss improved from inf to 0.56712, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 29s 719ms/step - loss: 0.7102 - accuracy: 0.5590 - val_loss: 0.5671 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.6135 - accuracy: 0.6590\n",
      "Epoch 2: val_loss improved from 0.56712 to 0.51526, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 27s 706ms/step - loss: 0.6135 - accuracy: 0.6590 - val_loss: 0.5153 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.6279 - accuracy: 0.6462\n",
      "Epoch 3: val_loss improved from 0.51526 to 0.47779, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 27s 709ms/step - loss: 0.6279 - accuracy: 0.6462 - val_loss: 0.4778 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.6024 - accuracy: 0.6692\n",
      "Epoch 4: val_loss improved from 0.47779 to 0.45403, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 28s 713ms/step - loss: 0.6024 - accuracy: 0.6692 - val_loss: 0.4540 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5600 - accuracy: 0.7282\n",
      "Epoch 5: val_loss improved from 0.45403 to 0.44650, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 27s 704ms/step - loss: 0.5600 - accuracy: 0.7282 - val_loss: 0.4465 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5579 - accuracy: 0.7154\n",
      "Epoch 6: val_loss improved from 0.44650 to 0.43397, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 27s 700ms/step - loss: 0.5579 - accuracy: 0.7154 - val_loss: 0.4340 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5725 - accuracy: 0.7154\n",
      "Epoch 7: val_loss improved from 0.43397 to 0.41485, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 27s 694ms/step - loss: 0.5725 - accuracy: 0.7154 - val_loss: 0.4148 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5431 - accuracy: 0.7487\n",
      "Epoch 8: val_loss improved from 0.41485 to 0.40611, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 29s 737ms/step - loss: 0.5431 - accuracy: 0.7487 - val_loss: 0.4061 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5514 - accuracy: 0.7051\n",
      "Epoch 9: val_loss improved from 0.40611 to 0.39131, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 28s 721ms/step - loss: 0.5514 - accuracy: 0.7051 - val_loss: 0.3913 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5379 - accuracy: 0.7359\n",
      "Epoch 10: val_loss improved from 0.39131 to 0.38863, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 27s 689ms/step - loss: 0.5379 - accuracy: 0.7359 - val_loss: 0.3886 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5183 - accuracy: 0.7615\n",
      "Epoch 11: val_loss improved from 0.38863 to 0.37423, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 27s 699ms/step - loss: 0.5183 - accuracy: 0.7615 - val_loss: 0.3742 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4997 - accuracy: 0.7359\n",
      "Epoch 12: val_loss did not improve from 0.37423\n",
      "39/39 [==============================] - 29s 740ms/step - loss: 0.4997 - accuracy: 0.7359 - val_loss: 0.3766 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5227 - accuracy: 0.7410\n",
      "Epoch 13: val_loss did not improve from 0.37423\n",
      "39/39 [==============================] - 29s 748ms/step - loss: 0.5227 - accuracy: 0.7410 - val_loss: 0.3753 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5202 - accuracy: 0.7487\n",
      "Epoch 14: val_loss improved from 0.37423 to 0.37323, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 32s 816ms/step - loss: 0.5202 - accuracy: 0.7487 - val_loss: 0.3732 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5066 - accuracy: 0.7615\n",
      "Epoch 15: val_loss improved from 0.37323 to 0.36065, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 33s 845ms/step - loss: 0.5066 - accuracy: 0.7615 - val_loss: 0.3606 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4680 - accuracy: 0.7923\n",
      "Epoch 16: val_loss improved from 0.36065 to 0.34447, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 32s 824ms/step - loss: 0.4680 - accuracy: 0.7923 - val_loss: 0.3445 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5183 - accuracy: 0.7385\n",
      "Epoch 17: val_loss did not improve from 0.34447\n",
      "39/39 [==============================] - 31s 787ms/step - loss: 0.5183 - accuracy: 0.7385 - val_loss: 0.3558 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4640 - accuracy: 0.7821\n",
      "Epoch 18: val_loss did not improve from 0.34447\n",
      "39/39 [==============================] - 31s 799ms/step - loss: 0.4640 - accuracy: 0.7821 - val_loss: 0.3449 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5021 - accuracy: 0.7564\n",
      "Epoch 19: val_loss improved from 0.34447 to 0.34233, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 33s 849ms/step - loss: 0.5021 - accuracy: 0.7564 - val_loss: 0.3423 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5488 - accuracy: 0.7179\n",
      "Epoch 20: val_loss improved from 0.34233 to 0.33070, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 33s 849ms/step - loss: 0.5488 - accuracy: 0.7179 - val_loss: 0.3307 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5305 - accuracy: 0.7436\n",
      "Epoch 21: val_loss did not improve from 0.33070\n",
      "39/39 [==============================] - 33s 842ms/step - loss: 0.5305 - accuracy: 0.7436 - val_loss: 0.3415 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 22/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4644 - accuracy: 0.7641\n",
      "Epoch 22: val_loss did not improve from 0.33070\n",
      "39/39 [==============================] - 33s 838ms/step - loss: 0.4644 - accuracy: 0.7641 - val_loss: 0.3330 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 23/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4687 - accuracy: 0.7692\n",
      "Epoch 23: val_loss improved from 0.33070 to 0.32247, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 34s 867ms/step - loss: 0.4687 - accuracy: 0.7692 - val_loss: 0.3225 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 24/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5111 - accuracy: 0.7513\n",
      "Epoch 24: val_loss improved from 0.32247 to 0.31216, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 32s 835ms/step - loss: 0.5111 - accuracy: 0.7513 - val_loss: 0.3122 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 25/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5170 - accuracy: 0.7282\n",
      "Epoch 25: val_loss improved from 0.31216 to 0.30642, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 32s 823ms/step - loss: 0.5170 - accuracy: 0.7282 - val_loss: 0.3064 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 26/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4708 - accuracy: 0.7897\n",
      "Epoch 26: val_loss did not improve from 0.30642\n",
      "39/39 [==============================] - 32s 830ms/step - loss: 0.4708 - accuracy: 0.7897 - val_loss: 0.3138 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 27/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.7949\n",
      "Epoch 27: val_loss improved from 0.30642 to 0.30580, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 33s 844ms/step - loss: 0.4506 - accuracy: 0.7949 - val_loss: 0.3058 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 28/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4368 - accuracy: 0.8000\n",
      "Epoch 28: val_loss improved from 0.30580 to 0.29080, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 35s 907ms/step - loss: 0.4368 - accuracy: 0.8000 - val_loss: 0.2908 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 29/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4927 - accuracy: 0.7410\n",
      "Epoch 29: val_loss did not improve from 0.29080\n",
      "39/39 [==============================] - 35s 898ms/step - loss: 0.4927 - accuracy: 0.7410 - val_loss: 0.3035 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 30/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4263 - accuracy: 0.7974\n",
      "Epoch 30: val_loss did not improve from 0.29080\n",
      "39/39 [==============================] - 36s 920ms/step - loss: 0.4263 - accuracy: 0.7974 - val_loss: 0.2987 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 31/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4561 - accuracy: 0.7872\n",
      "Epoch 31: val_loss improved from 0.29080 to 0.28937, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 33s 855ms/step - loss: 0.4561 - accuracy: 0.7872 - val_loss: 0.2894 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 32/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4755 - accuracy: 0.7615\n",
      "Epoch 32: val_loss improved from 0.28937 to 0.28275, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 36s 939ms/step - loss: 0.4755 - accuracy: 0.7615 - val_loss: 0.2827 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 33/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5235 - accuracy: 0.7538\n",
      "Epoch 33: val_loss did not improve from 0.28275\n",
      "39/39 [==============================] - 41s 1s/step - loss: 0.5235 - accuracy: 0.7538 - val_loss: 0.2971 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 34/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4774 - accuracy: 0.7615\n",
      "Epoch 34: val_loss did not improve from 0.28275\n",
      "39/39 [==============================] - 43s 1s/step - loss: 0.4774 - accuracy: 0.7615 - val_loss: 0.2867 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 35/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4446 - accuracy: 0.7769\n",
      "Epoch 35: val_loss improved from 0.28275 to 0.27666, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 44s 1s/step - loss: 0.4446 - accuracy: 0.7769 - val_loss: 0.2767 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 36/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4371 - accuracy: 0.7872\n",
      "Epoch 36: val_loss improved from 0.27666 to 0.27550, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 40s 1s/step - loss: 0.4371 - accuracy: 0.7872 - val_loss: 0.2755 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 37/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4659 - accuracy: 0.7846\n",
      "Epoch 37: val_loss did not improve from 0.27550\n",
      "39/39 [==============================] - 39s 993ms/step - loss: 0.4659 - accuracy: 0.7846 - val_loss: 0.2807 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 38/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4750 - accuracy: 0.7821\n",
      "Epoch 38: val_loss did not improve from 0.27550\n",
      "39/39 [==============================] - 40s 1s/step - loss: 0.4750 - accuracy: 0.7821 - val_loss: 0.2890 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 39/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4835 - accuracy: 0.7590\n",
      "Epoch 39: val_loss improved from 0.27550 to 0.27215, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 48s 1s/step - loss: 0.4835 - accuracy: 0.7590 - val_loss: 0.2721 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 40/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4709 - accuracy: 0.7897\n",
      "Epoch 40: val_loss did not improve from 0.27215\n",
      "39/39 [==============================] - 45s 1s/step - loss: 0.4709 - accuracy: 0.7897 - val_loss: 0.2788 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 41/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4823 - accuracy: 0.7718\n",
      "Epoch 41: val_loss did not improve from 0.27215\n",
      "39/39 [==============================] - 41s 1s/step - loss: 0.4823 - accuracy: 0.7718 - val_loss: 0.2785 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 42/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4579 - accuracy: 0.7846\n",
      "Epoch 42: val_loss improved from 0.27215 to 0.26371, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 41s 1s/step - loss: 0.4579 - accuracy: 0.7846 - val_loss: 0.2637 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 43/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4639 - accuracy: 0.7744\n",
      "Epoch 43: val_loss did not improve from 0.26371\n",
      "39/39 [==============================] - 42s 1s/step - loss: 0.4639 - accuracy: 0.7744 - val_loss: 0.2642 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 44/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4759 - accuracy: 0.7795\n",
      "Epoch 44: val_loss did not improve from 0.26371\n",
      "39/39 [==============================] - 38s 967ms/step - loss: 0.4759 - accuracy: 0.7795 - val_loss: 0.2650 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 45/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4872 - accuracy: 0.7538\n",
      "Epoch 45: val_loss did not improve from 0.26371\n",
      "39/39 [==============================] - 38s 977ms/step - loss: 0.4872 - accuracy: 0.7538 - val_loss: 0.2666 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 46/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4848 - accuracy: 0.7487\n",
      "Epoch 46: val_loss did not improve from 0.26371\n",
      "39/39 [==============================] - 39s 1s/step - loss: 0.4848 - accuracy: 0.7487 - val_loss: 0.2675 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 47/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4525 - accuracy: 0.7692\n",
      "Epoch 47: val_loss improved from 0.26371 to 0.25789, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 42s 1s/step - loss: 0.4525 - accuracy: 0.7692 - val_loss: 0.2579 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 48/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4629 - accuracy: 0.7615\n",
      "Epoch 48: val_loss improved from 0.25789 to 0.25582, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 48s 1s/step - loss: 0.4629 - accuracy: 0.7615 - val_loss: 0.2558 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 49/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5020 - accuracy: 0.7462\n",
      "Epoch 49: val_loss did not improve from 0.25582\n",
      "39/39 [==============================] - 43s 1s/step - loss: 0.5020 - accuracy: 0.7462 - val_loss: 0.2592 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 50/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4541 - accuracy: 0.7949\n",
      "Epoch 50: val_loss improved from 0.25582 to 0.25322, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 39s 1s/step - loss: 0.4541 - accuracy: 0.7949 - val_loss: 0.2532 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 51/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4726 - accuracy: 0.7692\n",
      "Epoch 51: val_loss did not improve from 0.25322\n",
      "39/39 [==============================] - 38s 980ms/step - loss: 0.4726 - accuracy: 0.7692 - val_loss: 0.2538 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 52/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4690 - accuracy: 0.7692\n",
      "Epoch 52: val_loss did not improve from 0.25322\n",
      "39/39 [==============================] - 39s 992ms/step - loss: 0.4690 - accuracy: 0.7692 - val_loss: 0.2532 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 53/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5126 - accuracy: 0.7333\n",
      "Epoch 53: val_loss improved from 0.25322 to 0.24987, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 39s 1s/step - loss: 0.5126 - accuracy: 0.7333 - val_loss: 0.2499 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 54/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.4570 - accuracy: 0.7846\n",
      "Epoch 54: val_loss improved from 0.24987 to 0.24116, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 37s 962ms/step - loss: 0.4570 - accuracy: 0.7846 - val_loss: 0.2412 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 55/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4622 - accuracy: 0.7667\n",
      "Epoch 55: val_loss improved from 0.24116 to 0.23931, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 36s 930ms/step - loss: 0.4622 - accuracy: 0.7667 - val_loss: 0.2393 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 56/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4505 - accuracy: 0.7872\n",
      "Epoch 56: val_loss did not improve from 0.23931\n",
      "39/39 [==============================] - 36s 917ms/step - loss: 0.4505 - accuracy: 0.7872 - val_loss: 0.2447 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 57/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4505 - accuracy: 0.7615\n",
      "Epoch 57: val_loss improved from 0.23931 to 0.23667, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 36s 933ms/step - loss: 0.4505 - accuracy: 0.7615 - val_loss: 0.2367 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 58/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4509 - accuracy: 0.7821\n",
      "Epoch 58: val_loss did not improve from 0.23667\n",
      "39/39 [==============================] - 36s 937ms/step - loss: 0.4509 - accuracy: 0.7821 - val_loss: 0.2371 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 59/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4734 - accuracy: 0.8051\n",
      "Epoch 59: val_loss did not improve from 0.23667\n",
      "39/39 [==============================] - 36s 939ms/step - loss: 0.4734 - accuracy: 0.8051 - val_loss: 0.2422 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 60/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4347 - accuracy: 0.8205\n",
      "Epoch 60: val_loss did not improve from 0.23667\n",
      "39/39 [==============================] - 36s 936ms/step - loss: 0.4347 - accuracy: 0.8205 - val_loss: 0.2377 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 61/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4485 - accuracy: 0.7821\n",
      "Epoch 61: val_loss did not improve from 0.23667\n",
      "39/39 [==============================] - 39s 1s/step - loss: 0.4485 - accuracy: 0.7821 - val_loss: 0.2392 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 62/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4411 - accuracy: 0.8051\n",
      "Epoch 62: val_loss improved from 0.23667 to 0.22106, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 38s 978ms/step - loss: 0.4411 - accuracy: 0.8051 - val_loss: 0.2211 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 63/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4810 - accuracy: 0.7846\n",
      "Epoch 63: val_loss improved from 0.22106 to 0.22041, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 38s 986ms/step - loss: 0.4810 - accuracy: 0.7846 - val_loss: 0.2204 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 64/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4515 - accuracy: 0.7846\n",
      "Epoch 64: val_loss did not improve from 0.22041\n",
      "39/39 [==============================] - 39s 1000ms/step - loss: 0.4515 - accuracy: 0.7846 - val_loss: 0.2267 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 65/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4824 - accuracy: 0.7436\n",
      "Epoch 65: val_loss improved from 0.22041 to 0.22009, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 39s 998ms/step - loss: 0.4824 - accuracy: 0.7436 - val_loss: 0.2201 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 66/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4667 - accuracy: 0.7641\n",
      "Epoch 66: val_loss did not improve from 0.22009\n",
      "39/39 [==============================] - 39s 995ms/step - loss: 0.4667 - accuracy: 0.7641 - val_loss: 0.2338 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 67/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4056 - accuracy: 0.8256\n",
      "Epoch 67: val_loss did not improve from 0.22009\n",
      "39/39 [==============================] - 38s 988ms/step - loss: 0.4056 - accuracy: 0.8256 - val_loss: 0.2235 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 68/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4309 - accuracy: 0.8077\n",
      "Epoch 68: val_loss did not improve from 0.22009\n",
      "39/39 [==============================] - 40s 1s/step - loss: 0.4309 - accuracy: 0.8077 - val_loss: 0.2273 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 69/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4275 - accuracy: 0.7718\n",
      "Epoch 69: val_loss improved from 0.22009 to 0.21250, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 40s 1s/step - loss: 0.4275 - accuracy: 0.7718 - val_loss: 0.2125 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 70/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4149 - accuracy: 0.8128\n",
      "Epoch 70: val_loss did not improve from 0.21250\n",
      "39/39 [==============================] - 40s 1s/step - loss: 0.4149 - accuracy: 0.8128 - val_loss: 0.2129 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 71/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5116 - accuracy: 0.7487\n",
      "Epoch 71: val_loss did not improve from 0.21250\n",
      "39/39 [==============================] - 41s 1s/step - loss: 0.5116 - accuracy: 0.7487 - val_loss: 0.2149 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 72/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4507 - accuracy: 0.7872\n",
      "Epoch 72: val_loss improved from 0.21250 to 0.21068, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 39s 1s/step - loss: 0.4507 - accuracy: 0.7872 - val_loss: 0.2107 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 73/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4340 - accuracy: 0.7923\n",
      "Epoch 73: val_loss improved from 0.21068 to 0.20634, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 41s 1s/step - loss: 0.4340 - accuracy: 0.7923 - val_loss: 0.2063 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 74/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4135 - accuracy: 0.8103\n",
      "Epoch 74: val_loss did not improve from 0.20634\n",
      "39/39 [==============================] - 41s 1s/step - loss: 0.4135 - accuracy: 0.8103 - val_loss: 0.2118 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 75/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4450 - accuracy: 0.8154\n",
      "Epoch 75: val_loss improved from 0.20634 to 0.20423, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 41s 1s/step - loss: 0.4450 - accuracy: 0.8154 - val_loss: 0.2042 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 76/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4539 - accuracy: 0.7718\n",
      "Epoch 76: val_loss did not improve from 0.20423\n",
      "39/39 [==============================] - 42s 1s/step - loss: 0.4539 - accuracy: 0.7718 - val_loss: 0.2058 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 77/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4707 - accuracy: 0.7718\n",
      "Epoch 77: val_loss did not improve from 0.20423\n",
      "39/39 [==============================] - 42s 1s/step - loss: 0.4707 - accuracy: 0.7718 - val_loss: 0.2079 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 78/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4358 - accuracy: 0.8103\n",
      "Epoch 78: val_loss did not improve from 0.20423\n",
      "39/39 [==============================] - 41s 1s/step - loss: 0.4358 - accuracy: 0.8103 - val_loss: 0.2046 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 79/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4530 - accuracy: 0.7872\n",
      "Epoch 79: val_loss improved from 0.20423 to 0.20245, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 44s 1s/step - loss: 0.4530 - accuracy: 0.7872 - val_loss: 0.2024 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 80/80\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.3852 - accuracy: 0.8282\n",
      "Epoch 80: val_loss improved from 0.20245 to 0.19514, saving model to embdmodel_1.hdf5\n",
      "39/39 [==============================] - 41s 1s/step - loss: 0.3852 - accuracy: 0.8282 - val_loss: 0.1951 - val_accuracy: 1.0000 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "batch_size=10\n",
    "specfilelist=os.listdir('/Users/prernachheda/Desktop/chord/test_spect/')\n",
    "specfilelist=['/Users/prernachheda/Desktop/chord/test_spect/'+filename for filename in specfilelist]\n",
    "specfilelist=shuffle(specfilelist)\n",
    "\n",
    "X_train=specfilelist[0:int(0.80*len(specfilelist))]\n",
    "X_test=specfilelist[int(0.80*len(specfilelist)):]\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6)\n",
    "es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "mc = ModelCheckpoint('embdmodel_1.hdf5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "history=siamese_net.fit_generator(batch_generator(X_train,batch_size),steps_per_epoch=len(X_train)//batch_size,epochs=80,validation_data=batch_generator(X_test,batch_size),\n",
    "                            validation_steps=len(X_test)//batch_size,callbacks=[reduce_lr,es,mc],shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cff5dae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
